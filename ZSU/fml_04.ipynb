{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fundamentals of Machine Learning - Exercise 4\n",
    "* Goal of the excercise is to learn how to use **K-means** implementation in the Scikit-learn library to perform clustering and subsequent cluster analysis on a Titanic dataset.\n",
    "\n",
    "## 🔎 Let's discuss the clustering topic a bit first\n",
    "* What task do clustering algorithms solve?\n",
    "* Do you know any examples of such algorithms?\n",
    "* What are the limitation of clustering algorithms?\n",
    "\n",
    "## 🔎 What is the **most difficult** of the clustering tasks?\n",
    "\n",
    "![meme01](https://github.com/rasvob/VSB-FEI-Fundamentals-of-Machine-Learning-Exercises/blob/master/images/fml_04_meme_01.jpg?raw=true)\n",
    "\n",
    "## 💡 But don't worry we will deal with the topic in several lectures 😊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries\n",
    "*🔎  What is the **sklearn** library?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6XOUhvFa-wT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.preprocessing, sklearn.cluster, sklearn.metrics\n",
    "import scipy.spatial\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# We will work with the famous Titanic dataset ⛵\n",
    "\n",
    "## Data Dictionary\n",
    "\n",
    "|Variable|Definition|Key|\n",
    "|:-------|:-------|:--------|\n",
    "|survival|Survival|0 = No, 1 = Yes|\n",
    "|pclass|Ticket class|1 = 1st, 2 = 2nd, 3 = 3rd|\n",
    "|sex|Sex||\n",
    "|Age|Age in years||\n",
    "|sibsp|# of siblings / spouses aboard the Titanic||\n",
    "|parch|# of parents / children aboard the Titanic||\n",
    "|ticket|Ticket number||\n",
    "|fare|Passenger fare||\n",
    "|cabin|Cabin number||\n",
    "|embarked|Port of Embarkation|C = Cherbourg, Q = Queenstown, S = Southampton|\n",
    "\n",
    "**pclass**: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "**age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "**sibsp**: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "**parch**: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "\n",
    "* Dataset is available at https://www.kaggle.com/competitions/titanic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "* https://raw.githubusercontent.com/rasvob/VSB-FEI-Fundamentals-of-Machine-Learning-Exercises/master/datasets/titanic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/rasvob/VSB-FEI-Fundamentals-of-Machine-Learning-Exercises/master/datasets/titanic.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many missing values do we have in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are going to cluster the passangers into defined number of groups\n",
    "* It is clear that it is mandatory to select only a relevant subset of features\n",
    "    * Name the new DF as *df_clustering* \n",
    "* 🔎 Is *Name* or *Ticket* relevant?\n",
    "    * 'Survived', 'Pclass','Sex','Age','SibSp','Parch','Fare','Embarked'\n",
    "\n",
    "1. Select the features\n",
    "2. Drop *NaN* values\n",
    "3. Change type of *Sex* and *Embarked* to string\n",
    "    * **astype()** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check *shape* and *dtypes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the dataset\n",
    "\n",
    "## 🔎 Does everything seem OK?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can see that not all features are numerical\n",
    "* 🔎 Is it a problem?\n",
    "    * Why?\n",
    "* 🔎 How to deal with it?\n",
    "\n",
    "## We have two basic encoding options\n",
    "* Ordinal encoding vs. One-hot encoding\n",
    "* What is the difference?\n",
    "    * Is thete difference in dimensionality change? Why it can be an issue?\n",
    "    * When is ordinal encoding appropriate?\n",
    "    * Can you omit the pre-requirements of ordinal encoding sometimes?\n",
    "\n",
    "## Lets encode categorical features\n",
    "* https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing\n",
    "* https://scikit-learn.org/stable/modules/classes.html?highlight=preprocessing#module-sklearn.preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 You may ask why do we use the `dataframe[['feature_name']]` notation with double `[[` and `]]` brackets\n",
    "* **Single brackets** pair around one variable name means that you want to select just the `pandas.Series` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering['Sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Double brackets** pair around one variable name created an output in the `pandas.DataFrame` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering[['Sex']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is OneHotEncoder as well, however I recommend using `pd.get_dummies` method instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's finish the encoding part and create a new dataframe with encoded data\n",
    "1. Create empty *df_encoded* dataframe with index using *df_clustering.index*\n",
    "2. Create *Sex* variable with ordinal encoded data\n",
    "3. Use `join` method for added one-hot encoded *Embarked* feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It is important to select the appropriate scaling method of the number features\n",
    "* There are many ways how to do this - **MinMax, StandardScaler, PowerTransform, ...**\n",
    "* This step heavily depends on a domain knowledge because the scales of the features have significant effect on a distances between couples of dataset instances\n",
    "    - It is clear that if one variable is in range **(0,1)** and the second one is in a range **(5000, 10 000)**, the difference in the **second feature** will be definitely **more important** than in the  first one from the numerical point of view\n",
    "    - Although it is possible that from the **domain point of view** the **first variable may be more important**\n",
    "    - 💡 Thus it is a good idea to at least transform the features into a **simiiar scales so the effect on the distance value would be similiar**\n",
    "    - Transformation depends heavily on the statistical distribution of the feature\n",
    "        - 💡You can use PowerTransform for a heavy-tailed distribution, **Standardization or MinMax normalization for normally distributed features** etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the *Fare* feature distribution\n",
    "* What transformation would be appropriate based on that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df_clustering.Fare, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the transformed feature into the *df_encoded* dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histogram of the transformer feature\n",
    "* 🔎 What has changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df_encoded.Fare, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the *Age* using MinMax scaler\n",
    "* `sklearn.preprocessing.minmax_scale`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the *df_encoded* and *['Survived', 'Pclass', 'SibSp', 'Parch']* features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# We finally got to the clustering part 😮‍💨\n",
    "\n",
    "![meme02](https://github.com/rasvob/VSB-FEI-Fundamentals-of-Machine-Learning-Exercises/blob/master/images/fml_04_meme_02.jpg?raw=true)\n",
    "\n",
    "## There are methods how to identify probable number of clusters in the data\n",
    "* It is always a rough estimate\n",
    "\n",
    "## 💡 We can use **Elbow method** to identify potentially ideal number of clusters in our data in **KMeans** algorithm.\n",
    "\n",
    "There are two basic methods for evaluation of clusters quality:\n",
    "1. SSE - Sum of squared distances of samples to their closest cluster center, this one is specific for **KMeans** algorithm.\n",
    "    * You can find it as **inertia_** attribute of KMeans sklearn object.\n",
    "2. Silhouette Coefficient - calculated using the mean intra-cluster distance and the mean nearest-cluster distance\n",
    "\n",
    "## 💡 We ussually want to find number of clusters with low SSE and high Silhoutte coef.\n",
    "- Take a look at [this](https://towardsdatascience.com/silhouette-coefficient-validating-clustering-techniques-e976bb81d10c) and [this](https://towardsdatascience.com/k-means-clustering-from-a-to-z-f6242a314e9a) for more details\n",
    "\n",
    "## Try different number of clusters from range <2, 10> for KMeans algorithm, save both evaluation criteria and plot dependency of criteria to number of clusters.\n",
    "* We will use `sklearn.cluster.KMeans` class\n",
    "* The most important parameter is the *n_clusters*\n",
    "    * What is the *random_state* parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_scores = []\n",
    "for k in range(2, 11):\n",
    "    clustering = sklearn.cluster.KMeans(n_clusters=k, random_state=13).fit(X)\n",
    "    clustering_scores.append({\n",
    "        'k': k,\n",
    "        'sse': clustering.inertia_,\n",
    "        'silhouette': sklearn.metrics.silhouette_score(X, clustering.labels_)\n",
    "    })\n",
    "df_clustering_scores = pd.DataFrame.from_dict(clustering_scores, orient='columns')\n",
    "df_clustering_scores = df_clustering_scores.set_index('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the SSE and Silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = df_clustering_scores, y='sse', x='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = df_clustering_scores, y='silhouette', x='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔎 What is the probable number of clusters in the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to analyze the data assigned into **4** clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How big are our clusters? How many 0, 1, .. are in *labels_* property?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📒 Explore clusters\n",
    "* Try to use cluster information for exploration analysis of our data\n",
    "    * Create new feature *cluster_id* with the *labels_* property data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Hint: You can use *sns.countplot* as a visual *.value_counts()* method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df_clustering, x='cluster_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Create plots showing values of different attributes based on cluster group and describe them\n",
    "* Let's follow the four example questions about the data to solve the task\n",
    "\n",
    "### ❓ Questions ❓\n",
    "1. Is **Fare** different for points in different clusters?\n",
    "    * 💡 Use *plt.yscale('log')* to take care of the outlier/variance effect\n",
    "2. Is **Age** different for point in different clusters?\n",
    "3. Does rate of suvival differ in clusters?\n",
    "    * *Survived*\n",
    "4. Does number of passanger of each class differ in clusters?\n",
    "    * *Pclass*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📝 Write a textual description of the four clusters\n",
    "\n",
    "### Cluster 1 - ...\n",
    "### Cluster 2 - ...\n",
    "### Cluster 3 - ...\n",
    "### Cluster 4 - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is our data represented in the best way?\n",
    "\n",
    "* **Clustering methods depends on calculation of distance metric among data points in our data matrix.**\n",
    "* Therefore it is necessary to preproces our data matrix **X** in a best way possible to achive equal distance for every dataset feature. \n",
    "    * After such transformation we can presume, that difference in *Age* has same impact as the difference as in the *Fare* feature.\n",
    "* **Generally, it is very hard to create perfect tranformation for our real dataset.**\n",
    "\n",
    "## Use StandardScaler transformation for our data **X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['Fare', 'Age', 'SibSp', 'Parch']\n",
    "enc = sklearn.preprocessing.StandardScaler()\n",
    "X_stand = pd.DataFrame(enc.fit_transform(df_clustering.loc[:, col_names]), columns = col_names, index=df_clustering.index)\n",
    "X_stand = pd.concat([X_stand, df_encoded.loc[:, ['Sex', 'Embarked_C', 'Embarked_Q', 'Embarked_S']], df_clustering.Survived], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stand.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✅ Task (2p)\n",
    "1. Use **KMeans** to differently preprocessed data matrix **X_stand**\n",
    "2. Detect \"ideal\" number of clusters using Elbow method\n",
    "3. Explore detected clusters and **describe** them to the Markdown cell\n",
    "    * **Describe the insight you got from the plots with a few sentences in a Markdown cell below the plot**\n",
    "        * ❌ Plot interpretation figured in real-time during task check is not allowed! ❌"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cv4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
